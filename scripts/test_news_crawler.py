#!/usr/bin/env python3
"""
ë‰´ìŠ¤ í¬ë¡¤ë§ ê¸°ëŠ¥ + DB ì‚½ì… ê¸°ëŠ¥ ê°„ë‹¨ í…ŒìŠ¤íŠ¸
"""

import sys
import os

# backend ëª¨ë“ˆ ê²½ë¡œë¥¼ PYTHONPATHì— ì¶”ê°€ (dockerÂ·ë¡œì»¬ ì–´ëŠ ê²½ë¡œë“ )
BACKEND_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'backend'))
if BACKEND_PATH not in sys.path:
    sys.path.insert(0, BACKEND_PATH)

import logging

try:
    from app import create_app
    from services.news_crawler import NewsCrawler
    from models import Artist
except ModuleNotFoundError as e:
    print("âŒ backend ëª¨ë“ˆ ë˜ëŠ” ì˜ì¡´ì„±ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("- backend, scripts í´ë”ì˜ ìƒëŒ€ ìœ„ì¹˜ê°€ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    print("- python scripts/test_news_crawler.py í˜•íƒœë¡œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
    print(f"ìƒì„¸ì˜¤ë¥˜: {e}")
    sys.exit(1)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_news_crawler():
    """ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸"""
    app = create_app()
    with app.app_context():
        # Test artist ìƒì„± ë˜ëŠ” ì¡°íšŒ (ì´ë¦„, DBì— ì—†ëŠ” ê²½ìš° ìƒˆë¡œ ì‚½ì…)
        artist = Artist.query.filter_by(name='ì†Œì§€ì„­').first()
        if not artist:
            artist = Artist(
                name='ì†Œì§€ì„­',
                real_name='ì†Œì§€ì„­',
                nationality='Korea',
                agency='Test Agency',
                status='active'
            )
            try:
                from app import db
            except ImportError:
                from backend.app import db
            db.session.add(artist)
            db.session.commit()
            logger.info("í…ŒìŠ¤íŠ¸ ì•„í‹°ìŠ¤íŠ¸ 'ì†Œì§€ì„­'ì„ ìƒˆë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        else:
            logger.info(f"ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ì•„í‹°ìŠ¤íŠ¸ ë°œê²¬: {artist.name}")

        # í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
        crawler = NewsCrawler()
        logger.info(f"{artist.name}ì˜ ìµœì‹  ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œë„...")

        try:
            news_items = crawler.search_news_for_artist(artist)
            logger.info(f"ê²€ìƒ‰ëœ ë‰´ìŠ¤ ê°œìˆ˜: {len(news_items)}")
            saved_count = crawler.save_news_to_db(news_items, artist)
            logger.info(f"DBì— ì €ì¥ëœ ë‰´ìŠ¤ ê°œìˆ˜: {saved_count}")

            try:
                from models import News
            except ImportError:
                from backend.models import News

            saved_news = News.query.filter_by(artist_id=artist.id).order_by(News.published_at.desc()).all()
            logger.info(f"DBì— ì €ì¥ëœ ì´ ë‰´ìŠ¤: {len(saved_news)}")

            for idx, news in enumerate(saved_news[:3]):
                logger.info(f"{idx+1}. {news.title}\n    URL: {news.url}\n    ì¶œì²˜: {news.source}\n    ë°œí–‰ì¼: {news.published_at}\n---")

        except Exception as err:
            logger.error(f"ë‰´ìŠ¤ í¬ë¡¤ë§ ë˜ëŠ” ì €ì¥ ì¤‘ ì˜¤ë¥˜: {err}")
            return False
        logger.info("âœ… ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True

if __name__ == "__main__":
    print("=== ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ê¸°ëŠ¥ & DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    print("âœ” Perplexity API KEYê°€ ë°˜ë“œì‹œ í™˜ê²½ ë³€ìˆ˜ì— ë“±ë¡ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
    print()
    try:
        success = test_news_crawler()
        print()
        if success:
            print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ: í¬ë¡¤ë§ ë° DB ì €ì¥ OK")
            sys.exit(0)
        else:
            print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - backend ëª¨ë“ˆÂ·DBÂ·API í‚¤ í™˜ê²½ ë“±ì„ í™•ì¸í•˜ì„¸ìš”.")
            sys.exit(1)
    except ModuleNotFoundError as e:
        print("âŒ backend ëª¨ë“ˆ ë˜ëŠ” ì˜ì¡´ì„±ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("- backend, scripts í´ë”ì˜ ìƒëŒ€ ìœ„ì¹˜ê°€ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        print("- ë°˜ë“œì‹œ python scripts/test_news_crawler.py í˜•íƒœë¡œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
        print(f"ìƒì„¸ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except Exception as ex:
        print("âŒ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ!")
        print(f"ìƒì„¸ì˜¤ë¥˜: {ex}")
        sys.exit(1)
